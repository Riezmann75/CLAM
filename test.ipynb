{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c07058",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2076677357.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "h5_dir = \"wsi_patches/BLCA/patches/\"\n",
    "h5_files = os.listdir(h5_dir)\n",
    "\n",
    "# Open the H5 file in read mode\n",
    "with h5py.File(\n",
    "    \"wsi_patches/BLCA/patches/TCGA-MV-A51V-01Z-00-DX1.5D626704-0803-4912-96D5-FB1EEFA509FB.h5\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    # Print the keys (top-level groups/datasets) in the file\n",
    "    print(\"Keys in H5 file:\", list(f.keys()))\n",
    "\n",
    "    # Access a specific group or dataset\n",
    "    # Replace 'your_group_or_dataset_key' with the actual key\n",
    "    print(f[\"coords\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff97cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this command in terminal\n",
    "\"python create_patches_fp.py --source DATA_DIRECTORY --save_dir RESULTS_DIRECTORY --patch_size 256 --seg --patch --stitch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4f4dba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openslide\n",
    "\n",
    "wsi = openslide.open_slide(\n",
    "    \"wsi_files/BLCA/TCGA-MV-A51V-01Z-00-DX1.5D626704-0803-4912-96D5-FB1EEFA509FB.svs\"\n",
    ")\n",
    "wsi.level_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c828d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "width, height = 256, 256\n",
    "full_image = wsi.read_region((1216, 6928), 0, (width, height))\n",
    "full_image = full_image.convert(\"RGB\")  # Convert RGBA to RGB\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((width, height)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "full_image = transform(full_image)\n",
    "full_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd84a1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8939f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587683fb",
   "metadata": {},
   "source": [
    "## Download data from GDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f89b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>md5</th>\n",
       "      <th>size</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c85e943d-6cca-4b5b-ab63-ad8ef320aefc</td>\n",
       "      <td>TCGA-BL-A13I-01Z-00-DX2.251412B0-EECB-420A-B96...</td>\n",
       "      <td>46bfa311930514a3d06f4deb89166c6a</td>\n",
       "      <td>552174543</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03414f4a-2121-4272-be1d-62c587d1ed26</td>\n",
       "      <td>TCGA-CF-A47S-01Z-00-DX1.1397F7C0-1098-4C42-B15...</td>\n",
       "      <td>111d59a5cf8ff9b5e563523f8eec2a40</td>\n",
       "      <td>1231578754</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67f49f95-8307-4157-b575-ec96bee225a8</td>\n",
       "      <td>TCGA-MV-A51V-01Z-00-DX1.5D626704-0803-4912-96D...</td>\n",
       "      <td>4216caeea91c5d8517239a6ddc434142</td>\n",
       "      <td>55379431</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cec56b4e-1f3c-48d3-81b5-a7c15984949a</td>\n",
       "      <td>TCGA-GU-AATO-01Z-00-DX1.1F0F2098-E4DF-4AA3-819...</td>\n",
       "      <td>112e0e398cd46e439976d90dc99a8822</td>\n",
       "      <td>1558004613</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6bd14fc-7e2c-41d2-aae3-7d510b58c105</td>\n",
       "      <td>TCGA-DK-A1AF-01Z-00-DX1.E18DE029-27A6-43A6-9E9...</td>\n",
       "      <td>dbfcb97f5e1309b2d9131526e278bf0d</td>\n",
       "      <td>2271582867</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  c85e943d-6cca-4b5b-ab63-ad8ef320aefc   \n",
       "1  03414f4a-2121-4272-be1d-62c587d1ed26   \n",
       "2  67f49f95-8307-4157-b575-ec96bee225a8   \n",
       "3  cec56b4e-1f3c-48d3-81b5-a7c15984949a   \n",
       "4  b6bd14fc-7e2c-41d2-aae3-7d510b58c105   \n",
       "\n",
       "                                            filename  \\\n",
       "0  TCGA-BL-A13I-01Z-00-DX2.251412B0-EECB-420A-B96...   \n",
       "1  TCGA-CF-A47S-01Z-00-DX1.1397F7C0-1098-4C42-B15...   \n",
       "2  TCGA-MV-A51V-01Z-00-DX1.5D626704-0803-4912-96D...   \n",
       "3  TCGA-GU-AATO-01Z-00-DX1.1F0F2098-E4DF-4AA3-819...   \n",
       "4  TCGA-DK-A1AF-01Z-00-DX1.E18DE029-27A6-43A6-9E9...   \n",
       "\n",
       "                                md5        size     state  \n",
       "0  46bfa311930514a3d06f4deb89166c6a   552174543  released  \n",
       "1  111d59a5cf8ff9b5e563523f8eec2a40  1231578754  released  \n",
       "2  4216caeea91c5d8517239a6ddc434142    55379431  released  \n",
       "3  112e0e398cd46e439976d90dc99a8822  1558004613  released  \n",
       "4  dbfcb97f5e1309b2d9131526e278bf0d  2271582867  released  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txt_file_path = \"gdc_manifest.2025-11-08.140931.txt\"\n",
    "manifest_file = pd.read_csv(txt_file_path, sep=\"\\t\")\n",
    "manifest_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ef84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_ids = [\n",
    "#     \"511e366e-de4b-49fc-a70d-99ccc4c464d5\",\n",
    "#     \"37a099ab-14d1-41c1-aa40-c823bba83dce\",\n",
    "#     \"c3b21f63-5c8a-4610-951f-ed62643fd355\",\n",
    "#     \"5e4ef3f3-5617-45bc-95ee-13fd5c6d0767\",\n",
    "# ]\n",
    "save_dir = \"./wsi_files/BLCA\"\n",
    "\n",
    "\n",
    "def download_svs(file_id, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    data_endpt = \"https://api.gdc.cancer.gov/data/{}\".format(file_id)\n",
    "\n",
    "    response = requests.get(\n",
    "        data_endpt, headers={\"Content-Type\": \"application/octet-stream\"}\n",
    "    )\n",
    "\n",
    "    # The file name can be found in the header within the Content-Disposition key.\n",
    "    response_head_cd = response.headers[\"Content-Disposition\"]\n",
    "\n",
    "    file_name = re.findall(\"filename=(.+)\", response_head_cd)[0]\n",
    "\n",
    "    with open(os.path.join(save_dir, file_name), \"wb\") as output_file:\n",
    "        output_file.write(response.content)\n",
    "\n",
    "\n",
    "# for file_id in file_ids:\n",
    "#     download_svs(file_id, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/457 [08:22<63:38:32, 502.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tqdm(manifest_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mdownload_svs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mdownload_svs\u001b[0;34m(file_id, save_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m data_endpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.gdc.cancer.gov/data/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(file_id)\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_endpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/octet-stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# The file name can be found in the header within the Content-Disposition key.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m response_head_cd \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Disposition\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/urllib3/response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/urllib3/response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/site-packages/urllib3/response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/http/client.py:464\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 464\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/media/storage1/giabao/miniconda3/envs/clam_latest/lib/python3.10/ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "open(\"wsi_files/BLCA/saved_ids.txt\", \"w\").close()\n",
    "for id in tqdm(manifest_file[\"id\"]):\n",
    "    download_svs(id, save_dir)\n",
    "    with open(\"wsi_files/BLCA/saved_ids.txt\", \"a\") as file:\n",
    "        file.write(id + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214c5b5",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1dab640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id\n",
       "TCGA-G2-AA3F    9\n",
       "TCGA-G2-A2EJ    8\n",
       "TCGA-G2-A2EO    8\n",
       "TCGA-G2-A2ES    7\n",
       "TCGA-FJ-A3Z7    6\n",
       "               ..\n",
       "TCGA-ZF-AA4T    1\n",
       "TCGA-ZF-AA4U    1\n",
       "TCGA-ZF-A9R3    1\n",
       "TCGA-ZF-A9R4    1\n",
       "TCGA-ZF-A9R5    1\n",
       "Name: count, Length: 373, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv(\"tcga_blca_all_clean.csv\")\n",
    "df[\"case_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b078a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'slide_id', 'site', 'is_female', 'oncotree_code', 'age',\n",
       "       'survival_months', 'censorship', 'train', 'NDUFS5_cnv',\n",
       "       ...\n",
       "       'ZWINT_rnaseq', 'ZXDA_rnaseq', 'ZXDB_rnaseq', 'ZXDC_rnaseq',\n",
       "       'ZYG11A_rnaseq', 'ZYG11B_rnaseq', 'ZYX_rnaseq', 'ZZEF1_rnaseq',\n",
       "       'ZZZ3_rnaseq', 'TPTEP1_rnaseq'],\n",
       "      dtype='object', length=20404)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da50b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.drop(columns=[\"site\", \"oncotree_code\", \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de8a0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival_months</th>\n",
       "      <th>censorship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>69.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival_months  censorship\n",
       "0              7.33           0\n",
       "1              2.66           0\n",
       "2              5.06           0\n",
       "3             10.94           1\n",
       "4             17.61           1\n",
       "5              8.94           0\n",
       "6             10.64           0\n",
       "7             19.38           1\n",
       "8             63.96           1\n",
       "9             12.16           0\n",
       "10             9.07           1\n",
       "11            13.47           1\n",
       "12            69.28           1\n",
       "13            51.28           1\n",
       "14            17.87           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the patients in file_ids\n",
    "wsi_path = \"./wsi_files/BLCA/\"\n",
    "slide_ids = [file_id for file_id in os.listdir(wsi_path) if file_id.endswith(\".svs\")]\n",
    "case_ids = [slide_id.split(\"-01Z\")[0] for slide_id in slide_ids]\n",
    "df_filtered = df_filtered[df_filtered[\"slide_id\"].isin(slide_ids)]\n",
    "df_filtered[[\"survival_months\", \"censorship\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519168e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(columns=[\"slide_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5768c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_cols = [\"survival_months\", \"censorship\"]\n",
    "feature_cols = [col for col in df_filtered.columns if col not in clinical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93a44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find categorical and numerical columns\n",
    "categorical_cols = [\"is_female\"]\n",
    "numeric_cols = []\n",
    "for col in feature_cols:\n",
    "    if col not in categorical_cols:\n",
    "        numeric_cols.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7140d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_filtered[df_filtered[\"case_id\"] == case_ids[0]].iloc[0]\n",
    "df1 = df1[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2602af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 20398), (3, 20398))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_filtered[feature_cols]\n",
    "y = df_filtered[clinical_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50ae235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'is_female', 'age', 'NDUFS5_cnv', 'MACF1_cnv',\n",
       "       'RNA5SP44_cnv', 'KIAA0754_cnv', 'BMP8A_cnv', 'PABPC4_cnv',\n",
       "       'SNORA55_cnv',\n",
       "       ...\n",
       "       'ZWINT_rnaseq', 'ZXDA_rnaseq', 'ZXDB_rnaseq', 'ZXDC_rnaseq',\n",
       "       'ZYG11A_rnaseq', 'ZYG11B_rnaseq', 'ZYX_rnaseq', 'ZZEF1_rnaseq',\n",
       "       'ZZZ3_rnaseq', 'TPTEP1_rnaseq'],\n",
       "      dtype='object', length=20398)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c90db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# import torch\n",
    "# import openslide\n",
    "# import h5py\n",
    "# from torchvision import transforms\n",
    "\n",
    "# class PatientDataset(Dataset):\n",
    "#     def __init__(self, case_ids: list[str], h5_files: list[str], X, y):\n",
    "#         self.case_ids = case_ids\n",
    "#         self.h5_files = h5_files\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.patches = []\n",
    "#         self.clinical_cols = [\"survival_months\", \"censorship\"]\n",
    "#         self.feature_cols = [\n",
    "#             col for col in self.X.columns if col not in self.clinical_cols\n",
    "#         ]\n",
    "#         self.feature_cols.remove(\"case_id\")\n",
    "#         for h5_file in h5_files:\n",
    "#             assert os.path.exists(h5_file), f\"H5 file {h5_file} does not exist.\"\n",
    "#         for case_id in case_ids:\n",
    "#             for h5_file in h5_files:\n",
    "#                 if case_id not in h5_file:\n",
    "#                     continue\n",
    "#                 data = h5py.File(h5_file, \"r\")\n",
    "#                 wsi = openslide.open_slide(\n",
    "#                     f\"wsi_files/BLCA/{h5_file.split('/')[-1].split('.h5')[0]}.svs\"\n",
    "#                 )\n",
    "#                 patches = []\n",
    "#                 for coord in data[\"coords\"][:]:\n",
    "#                     patch = wsi.read_region(coord, 2, (256, 256)).convert(\"RGB\")\n",
    "#                     tensor_patch = transforms.ToTensor()(patch)\n",
    "#                     patches.append(tensor_patch)\n",
    "#                 self.patches.append(patches)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.case_ids)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         patches = self.patches[idx]  # patches for one patient\n",
    "#         case_id = self.case_ids[idx]\n",
    "#         patient = self.X[self.X[\"case_id\"] == case_id].iloc[0]\n",
    "#         patient = patient[self.feature_cols]\n",
    "#         patient = torch.tensor(patient.values.astype(float))\n",
    "#         return (patient, patches), torch.tensor(self.y.iloc[idx].values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e05d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import openslide\n",
    "import h5py\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, case_ids: list[str], h5_files: list[str], X, y):\n",
    "        self.case_ids = case_ids\n",
    "        self.h5_files = h5_files\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.patches = []\n",
    "        self.clinical_cols = [\"survival_months\", \"censorship\"]\n",
    "        self.feature_cols = [\n",
    "            col for col in self.X.columns if col not in self.clinical_cols\n",
    "        ]\n",
    "        self.feature_cols.remove(\"case_id\")\n",
    "        self.patch_features = []\n",
    "        for h5_file in h5_files:\n",
    "            assert os.path.exists(h5_file), f\"H5 file {h5_file} does not exist.\"\n",
    "        for case_id in case_ids:\n",
    "            # load tensor from extracted features\n",
    "            extracted_path = f\"wsi_patches/BLCA/features/{case_id}.pt\"\n",
    "            features = torch.load(extracted_path)\n",
    "            self.patch_features.append(features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch_features = self.patch_features[idx]\n",
    "        case_id = self.case_ids[idx]\n",
    "        patient = self.X[self.X[\"case_id\"] == case_id].iloc[0]\n",
    "        patient = patient[self.feature_cols]\n",
    "        patient = torch.tensor(patient.values.astype(float))\n",
    "        return (patient, patch_features), torch.tensor(self.y.iloc[idx].values.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c9c86",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90885811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e096c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologicalEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 128):\n",
    "        super(PathologicalEncoder, self).__init__()\n",
    "        self.fc = nn.LazyLinear(hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6956e",
   "metadata": {},
   "source": [
    "For each image $i$, the number patches per image is: $M_i$. After computing self-attention, the shape is: $M_i \\times d$. After that, we use the mean pooling to summarize the attention into an image feature vector of size $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca678b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGenomicEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, categorical_cols: list[str], numeric_cols: list[str]\n",
    "    ):\n",
    "        super(BaseGenomicEncoder, self).__init__()\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.numerical_cols = numeric_cols\n",
    "        self.features = self.numerical_cols + self.categorical_cols\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        for col in self.categorical_cols:\n",
    "            num_unique_values = int(df[col].nunique())\n",
    "            embedding_size = 4\n",
    "            self.embeddings[col] = nn.Embedding(num_unique_values, embedding_size)\n",
    "\n",
    "    def categorical_name_to_index(self, col):\n",
    "        return self.categorical_cols.index(col)\n",
    "\n",
    "    def numerical_name_to_index(self, col):\n",
    "        return self.numerical_cols.index(col)\n",
    "\n",
    "    def categorical_index_to_name(self, index):\n",
    "        return self.categorical_cols[index]\n",
    "\n",
    "    def numerical_index_to_name(self, index):\n",
    "        return self.numerical_cols[index]\n",
    "\n",
    "    def embed(self, x):\n",
    "        embedded_cols = []\n",
    "        for col in self.categorical_cols:\n",
    "            # ndarray = np.array()\n",
    "            embedded_col = self.embeddings[col](\n",
    "                x[:, self.categorical_name_to_index(col)].long()\n",
    "            )\n",
    "            # print(embedded_col.shape)\n",
    "            embedded_cols.append(embedded_col)\n",
    "        numerical_data = torch.stack(\n",
    "            [x[:, self.numerical_name_to_index(col)] for col in self.numerical_cols],\n",
    "            dim=1,\n",
    "        ).float()\n",
    "        x = torch.cat(embedded_cols + [numerical_data], dim=1)\n",
    "        return x\n",
    "\n",
    "    def embed_with_time(self, x, t):\n",
    "        time_data = torch.reshape(t, (x.shape[0], 1)).float()\n",
    "        x = self.embed(x)\n",
    "        x = torch.cat((x, time_data), dim=1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"Forward method not implemented!\")\n",
    "\n",
    "\n",
    "class GenomicEncoder(BaseGenomicEncoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        categorical_cols: list[str],\n",
    "        numeric_cols: list[str],\n",
    "        bias=True,\n",
    "        hidden_dim: int = 128,\n",
    "    ):\n",
    "        super().__init__(df, categorical_cols, numeric_cols)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.LazyLinear(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LazyLinear(128),\n",
    "        )\n",
    "        self.fc = nn.LazyLinear(hidden_dim)\n",
    "\n",
    "        # self.bias = nn.Sequential(nn.LazyLinear(32), nn.ReLU(), nn.LazyLinear(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.net(x)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "# loss\n",
    "class NLL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, preds, failure_times, is_observed):\n",
    "        # Number of observed events\n",
    "        return (\n",
    "            1\n",
    "            / len(preds)\n",
    "            * torch.sum(torch.exp(preds) * failure_times - is_observed * preds, dim=0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46107498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_encoder: PathologicalEncoder,\n",
    "        geno_encoder: GenomicEncoder,\n",
    "        hidden_dim: int = 128,\n",
    "    ):\n",
    "        super(SurvivalModel, self).__init__()\n",
    "        self.path_encoder = path_encoder\n",
    "        self.geno_encoder = geno_encoder\n",
    "        self.fc = nn.LazyLinear(1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.path_msa = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, num_heads=4, batch_first=True\n",
    "        )\n",
    "        self.geno_msa = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, num_heads=4, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, path_x, geno_x, mask):\n",
    "        # path_x shape: Batch size x #patches x Feature dim\n",
    "        # flatten:\n",
    "        B, N, D = path_x.shape\n",
    "        path_x = path_x.view(-1, D)  # shape: (Batch size * Num patches) x Feature dim\n",
    "        # geno_x shape: Batch size x Num genomic features\n",
    "        path_features = self.path_encoder(\n",
    "            path_x\n",
    "        )  # shape: (Batch size * Num patches) x Feature dim\n",
    "        path_features = path_features.view(\n",
    "            B, N, -1\n",
    "        )  # shape: Batch size x Num patches x Feature dim\n",
    "        geno_features = self.geno_encoder(geno_x)  # shape: Batch size x Feature dim\n",
    "\n",
    "        # Self Attention Mechanism\n",
    "        path_attended, _ = self.path_msa(\n",
    "            path_features, path_features, path_features, key_padding_mask=mask\n",
    "        )  # shape: Batch size x Num patches x Feature dim\n",
    "        path_representation = torch.mean(\n",
    "            path_attended, dim=1\n",
    "        )  # shape: Batch size x Feature dim\n",
    "        geno_features = geno_features.view(B, -1)  # shape: Batch size x Feature dim\n",
    "        # concat path and genomic features\n",
    "        combined_features = torch.cat(\n",
    "            (path_representation, geno_features), dim=1\n",
    "        )  # shape: Batch size x (2 * Feature dim)\n",
    "        preds = self.fc(combined_features)  # shape: Batch size x 1\n",
    "        return preds.squeeze()  # shape: Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee190a8a",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6979af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dir = \"wsi_patches/BLCA/patches/\"\n",
    "h5_files = os.listdir(h5_dir)\n",
    "\n",
    "case_ids = [h5_file.split(\"-01Z\")[0] for h5_file in h5_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84aff540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered[feature_cols]\n",
    "y = df_filtered[clinical_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc548b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_case_ids = X_train[\"case_id\"].to_list()\n",
    "test_case_ids = X_test[\"case_id\"].to_list()\n",
    "train_h5_files = [\n",
    "    os.path.join(h5_dir, h5_file)\n",
    "    for h5_file in h5_files\n",
    "    if h5_file.split(\"-01Z\")[0] in train_case_ids\n",
    "]\n",
    "test_h5_files = [\n",
    "    os.path.join(h5_dir, h5_file)\n",
    "    for h5_file in h5_files\n",
    "    if h5_file.split(\"-01Z\")[0] in test_case_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059ff5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    patients, patches, clinical_outcomes = [], [], []\n",
    "    for (patient, image_patches), clinical_outcome in batch:\n",
    "        patients.append(patient)\n",
    "        patches.append(image_patches)\n",
    "        clinical_outcomes.append(clinical_outcome)\n",
    "    max_num_patches = max([patch.shape[0] for patch in patches])\n",
    "    mask = torch.zeros(len(patches), max_num_patches, dtype=torch.bool)\n",
    "    for i, patch in enumerate(patches):\n",
    "        mask[i, : patch.shape[0]] = True\n",
    "\n",
    "    patients = torch.stack(patients)\n",
    "    patches = pad_sequence(patches, batch_first=True)\n",
    "\n",
    "    clinical_outcomes = torch.stack(clinical_outcomes)\n",
    "    return patients, patches, clinical_outcomes, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eac35ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PatientDataset(\n",
    "    train_case_ids,\n",
    "    train_h5_files,\n",
    "    X_train.reset_index(drop=True),\n",
    "    y_train.reset_index(drop=True),\n",
    ")\n",
    "test_dataset = PatientDataset(\n",
    "    test_case_ids,\n",
    "    test_h5_files,\n",
    "    X_test.reset_index(drop=True),\n",
    "    y_test.reset_index(drop=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5507060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7508f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients, patches, clinical_outcomes, mask = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc96c737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267,  0.0806,  0.1579,  ...,  0.0932, -0.0733, -0.0191],\n",
       "        [-0.1879,  0.5568,  0.4099,  ...,  1.1018,  0.2168,  0.7740],\n",
       "        [-0.0252,  0.1402,  0.1855,  ...,  0.1989,  0.0407,  0.0255],\n",
       "        ...,\n",
       "        [ 0.0136, -0.0237,  0.1997,  ...,  0.0925, -0.0893,  0.0490],\n",
       "        [-0.0164,  0.1039,  0.1222,  ...,  0.1967, -0.0741,  0.0221],\n",
       "        [-0.2093,  0.1398,  0.1696,  ..., -0.0502,  0.1029, -0.0734]],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno_encoder = GenomicEncoder(\n",
    "    df=df_filtered,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols,\n",
    "    hidden_dim=128,\n",
    ")\n",
    "geno_encoder(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "712c5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 20397]),\n",
       " torch.Size([8, 413, 2048]),\n",
       " torch.Size([8, 2]),\n",
       " torch.Size([8, 413]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.shape, patches.shape, clinical_outcomes.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03c89770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of categorical and numerical columns\n",
    "categorical_cols_idx = [feature_cols.index(col) for col in categorical_cols]\n",
    "numeric_cols_idx = [feature_cols.index(col) for col in numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a7c7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_enc = PathologicalEncoder(hidden_dim=128)\n",
    "geno_enc = GenomicEncoder(\n",
    "    df_filtered,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols,\n",
    "    hidden_dim=128,\n",
    ")\n",
    "survival_model = SurvivalModel(\n",
    "    path_encoder=path_enc,\n",
    "    geno_encoder=geno_enc,\n",
    "    hidden_dim=128,\n",
    ")\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "survival_model = survival_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98bde58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "lr = 0.0005\n",
    "optimizer = Adam(survival_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "loss = NLL()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f5eff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for patient, patches, clinical_outcomes, mask in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            patches = patches.to(device)\n",
    "            patient = patient.to(device)\n",
    "            clinical_outcomes = clinical_outcomes.to(device)\n",
    "            mask = ~mask.to(device)  # invert mask for key_padding_mask\n",
    "            preds = model(patches, patient, mask)\n",
    "            failure_times = clinical_outcomes[:, 0]\n",
    "            is_observed = clinical_outcomes[:, 1]\n",
    "            current_loss = loss(preds, failure_times, is_observed)\n",
    "            current_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += current_loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed1561e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f31d1ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 20.3452\n",
      "Epoch 2/10, Loss: 3.5865\n",
      "Epoch 3/10, Loss: 2.7761\n",
      "Epoch 4/10, Loss: 3.0143\n",
      "Epoch 5/10, Loss: 3.8023\n",
      "Epoch 6/10, Loss: 4.2184\n",
      "Epoch 7/10, Loss: 3.4105\n",
      "Epoch 8/10, Loss: 3.7831\n",
      "Epoch 9/10, Loss: 2.7460\n",
      "Epoch 10/10, Loss: 3.4222\n"
     ]
    }
   ],
   "source": [
    "train(survival_model, optimizer, loss, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ed9aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.metrics import c_index\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=len(train_dataset), shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "survival_model.eval()\n",
    "collected_preds = []\n",
    "clinical_outcomes_list = []\n",
    "with torch.no_grad():\n",
    "    for patient, patches, clinical_outcomes, mask in train_loader:\n",
    "        patches = patches.to(device)\n",
    "        patient = patient.to(device)\n",
    "        clinical_outcomes = clinical_outcomes.to(device)\n",
    "        mask = ~mask.to(device)  # invert mask for key_padding_mask\n",
    "        preds = survival_model(patches, patient, mask)\n",
    "        collected_preds.append(preds.cpu())\n",
    "        clinical_outcomes_list.append(clinical_outcomes.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4388b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_outcomes_list = torch.stack(clinical_outcomes_list)\n",
    "clinical_outcomes_list = clinical_outcomes_list.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68d6e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_preds = torch.stack(collected_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16156585",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_outcomes_list = clinical_outcomes_list.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a001fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 2]), torch.Size([1, 12]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_outcomes_list.shape, collected_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c806ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train C-index: 0.9200\n"
     ]
    }
   ],
   "source": [
    "train_c_index_value = c_index(\n",
    "    collected_preds, clinical_outcomes_list[:, 0], clinical_outcomes_list[:, 1]\n",
    ")\n",
    "print(f\"Train C-index: {train_c_index_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2dc55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
